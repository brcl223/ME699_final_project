\section{Control}
	\subsection{Global Stability}
		Using the dynamics of the n-link manipulator described in Eq. \ref{eom-manipulator}, we will design an adaptive PD controller with the goal of reaching the desired task space. In order to ensure that we can do this in a stable manner, we derive our control law using Lyapunov stability analysis. To do this, consider the Lyapunov candidate
		\begin{equation}
			V(t) = \frac{1}{2}\left(\dot{\tilde{q}}^{T}M(q)\ddot{\tilde{q}} + \tilde{a}^{T}\Gamma\tilde{a} + \tilde{q}K_{p}\tilde{q}\right)
			\label{eq:lyapcandidate}
		\end{equation}
		where $a\in\mathbb{R}^{m\times1}$ are the unknown manipulator parameters, $K_{p}, \Gamma\in\mathbb{R}^{m\times m}$ are positive definite and symmetric, $\tilde{q}$ is the error between the current space and desired task space, and $\tilde{a}$ is the error in our estimation of unknown parameters. To understand how candidate \ref{eq:lyapcandidate} changes over time, we differentiate to obtain
		\begin{equation}
			\dot{V}(t) = \dot{\tilde{q}}^{T}\left[ \tau - M(q)\ddot{q}_{d} - C(q,\dot{Q})\dot{q}_{d} - G(q) + K_{p}\tilde{q} \right] + \tilde{a}^{T}\Gamma\dot{\tilde{a}}
			\label{eq:vDot}
		\end{equation}
		where $q_{d}\in\mathbb{R}^{n\times1}$ is the desired trajectory of joint properties. We then select the control law to be
		\begin{equation}
			\tau = \hat{M}\ddot{q}_{d} + \hat{C}(q,\dot{q})\dot{q}_{d} + \hat{G}(q)	- K_{d}\dot{\tilde{q}}
			\label{eq:controlLaw}
		\end{equation}
		where $K_{D}$ is positive definite and symmetric. Choosing the control law in this manner allows our estimation vector, $a$, to be dependent only upon unknown paramters of the manipulator. We can then re-write Eq. \ref{eq:vDot} in terms of our state error as
		\begin{equation}
			\dot{V}(t) = \dot{\tilde{q}}^{T}\left[ \tilde{M}(q)\ddot{q}_{d} + \tilde{C}(q,\dot{q})\dot{q}_{d} + \tilde{G}(q) - K_{D}\dot{\tilde{q}} \right] + \tilde{a}^{T}\Gamma\dot{\tilde{a}}
			\label{eq:vDotControl}
		\end{equation}
		Note that since our state matrices are linear we can further simplify to obtain
		\begin{equation}
			\dot{V}(t) = -\dot{\tilde{q}}^{T}K_{D}\dot{\tilde{q}} + \tilde{a}^{T}\left[\Gamma\dot{\tilde{a}} + Y^{T}\dot{\tilde{q}} \right]
		\end{equation}
		Thus, for a reasonably close approximation of our state matrices, we can select our gains, $K_{D}$ such that we obtain a globally stable controller.
		
	\subsection{Implementation}
		In order to implement this control law, we will first need a desired task space consisting of joint displacements, velocities and accelerations. Once we have these parameters, we will simulate sensors to measure these values as well as a random number generator to replicate sensor noise. These sensor values will then be passed into the Kalman filter to eliminate as much noise as possible. Once this process is complete, the state will be updated and passed into the controller for the appropriate action to be taken.

